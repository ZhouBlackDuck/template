## ğŸ“‚ é¡¹ç›®ç»“æ„

```
template/
â”œâ”€â”€ ğŸ“ conf/                    # âš™ï¸ Hydra é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yaml             # ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ ğŸ“ model/               # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ data/                # æ•°æ®é›†é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ optimizer/           # ä¼˜åŒ–å™¨é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ trainer/             # Trainer é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ logger/              # Logger é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ train/               # è®­ç»ƒå‚æ•°
â”‚   â””â”€â”€ ğŸ“ custom/              # è‡ªå®šä¹‰è„šæœ¬é…ç½®
â”‚
â”œâ”€â”€ ğŸ“ src/                     # ğŸ’» æºä»£ç 
â”‚   â”œâ”€â”€ train.py                # è®­ç»ƒå…¥å£
â”‚   â”œâ”€â”€ ğŸ“ models/              # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ ğŸ“ datasets/            # æ•°æ®æ¨¡å—
â”‚   â””â”€â”€ ğŸ“ utils/               # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ ğŸ“ data/                    # ğŸ“Š æ•°æ®é›†ç›®å½•
â”œâ”€â”€ ğŸ“ outputs/                 # ğŸ“¤ è¾“å‡ºç›®å½•
â””â”€â”€ ğŸ“„ requirements.txt         # ä¾èµ–åˆ—è¡¨
```

---

## ğŸ› ï¸ å®‰è£…

### 1ï¸âƒ£ å…‹éš†ä»“åº“

```bash
git clone <repo-url>
cd template
```

### 2ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

### 3ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ‹ï¸ è®­ç»ƒæ¨¡å‹

```bash
cd src
python train.py
```

---

## âš™ï¸ é…ç½®ç³»ç»Ÿ

æœ¬é¡¹ç›®ä½¿ç”¨ **Hydra** è¿›è¡Œé…ç½®ç®¡ç†ï¼Œæ”¯æŒçµæ´»çš„é…ç½®ç»„åˆå’Œå‘½ä»¤è¡Œè¦†ç›–ã€‚

### ğŸ“ ä¸»é…ç½®æ–‡ä»¶

```yaml
# conf/config.yaml
defaults:
  - model: mlp           # æ¨¡å‹é…ç½®
  - data: mnist          # æ•°æ®é›†é…ç½®
  - optimizer: adam      # ä¼˜åŒ–å™¨é…ç½®
  - logger: tensorboard  # æ—¥å¿—è®°å½•å™¨
  - trainer: default     # Trainer é…ç½®
  - train: default       # è®­ç»ƒå‚æ•°
  - custom: default      # è‡ªå®šä¹‰è„šæœ¬é…ç½®

seed: 42                 # éšæœºç§å­
```

### ğŸ”„ å‘½ä»¤è¡Œè¦†ç›–å‚æ•°

```bash
# ä¿®æ”¹å•ä¸ªå‚æ•°
python train.py trainer.max_epochs=50

# ä¿®æ”¹å¤šä¸ªå‚æ•°
python train.py optimizer.lr=0.0001 data.batch_size=128

# åˆ‡æ¢é…ç½®ç»„
python train.py model=mlp data=mnist

# ç»„åˆä½¿ç”¨
python train.py trainer.max_epochs=100 optimizer.lr=0.0005 seed=123
```

---

## ğŸ“Š æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

ä½¿ç”¨ TensorBoard å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼š

```bash
tensorboard --logdir outputs/train/
```

ç„¶ååœ¨æµè§ˆå™¨è®¿é—® `http://localhost:6006` ğŸŒ

---

## ğŸ”§ æ‰©å±•æŒ‡å—

### ğŸ“¦ æ·»åŠ æ–°æ¨¡å‹

1ï¸âƒ£ åœ¨ `src/models/` ä¸‹åˆ›å»ºæ¨¡å‹æ–‡ä»¶ï¼š

```python
# src/models/my_model.py
import pytorch_lightning as pl


class MyModel(pl.LightningModule):
    def __init__(self, **kwargs):
        super().__init__()
        # å®šä¹‰æ¨¡å‹ç»“æ„
        ...
    
    def forward(self, x):
        ...
    
    def training_step(self, batch, batch_idx):
        ...
    
    def configure_optimizers(self):
        ...
```

2ï¸âƒ£ åˆ›å»ºé…ç½®æ–‡ä»¶ `conf/model/my_model.yaml`ï¼š

```yaml
_target_: models.my_model.MyModel

# æ¨¡å‹å‚æ•°
param1: value1
param2: value2
```

3ï¸âƒ£ ä½¿ç”¨æ–°æ¨¡å‹è®­ç»ƒï¼š

```bash
python train.py model=my_model
```

### ğŸ“Š æ·»åŠ æ–°æ•°æ®é›†

1ï¸âƒ£ åœ¨ `src/datasets/` ä¸‹åˆ›å»ºæ•°æ®æ¨¡å—ï¼š

```python
# src/datasets/my_data.py
import pytorch_lightning as pl


class MyDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        super().__init__()
        ...
    
    def prepare_data(self):
        # ä¸‹è½½æ•°æ®
        ...
    
    def setup(self, stage=None):
        # è®¾ç½®æ•°æ®é›†
        ...
    
    def train_dataloader(self):
        ...
    
    def val_dataloader(self):
        ...
```

2ï¸âƒ£ åˆ›å»ºé…ç½®æ–‡ä»¶ `conf/data/my_data.yaml`

---

## ğŸ’¡ æç¤º

- ğŸ“ é€šè¿‡ `--cfg job` æŸ¥çœ‹å®Œæ•´é…ç½®ï¼š`python train.py --cfg job`
- ğŸ” ä½¿ç”¨ `--help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨é…ç½®é€‰é¡¹
- ğŸ’¾ æ£€æŸ¥ç‚¹è·¯å¾„æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
